{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Autoencoder in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are autoecnoders?\n",
    "![title](img/autoencoder_schema.jpg)\n",
    "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#the imports\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Are they good at data compression?\n",
    "Usually, not really. In picture compression for instance, it is pretty difficult to train an autoencoder that does a better job than a basic algorithm like JPEG, and typically the only way it can be achieved is by restricting yourself to a very specific type of picture (e.g. one for which JPEG does not do a good job). The fact that autoencoders are data-specific makes them generally impractical for real-world data compression problems: you can only use them on data that is similar to what they were trained on, and making them more general thus requires lots of training data. But future advances might change this, who knows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are autoencoders good for?\n",
    "Today two interesting practical applications of autoencoders are:\n",
    "1. data denoising, \n",
    "2. non linear dimensionality reduction for data visualization. With appropriate dimensionality and sparsity constraints,autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n",
    "3. Reinforcement Learning\n",
    "4. Seemi-Supervised Learning, we have lots of unlabeled data and some labeled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build the simplest possible autoencoder\n",
    "\n",
    "We'll start simple, with a single fully-connected neural layer as encoder and as decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "#autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s - loss: 0.3719 - val_loss: 0.2726\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2655 - val_loss: 0.2555\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2457 - val_loss: 0.2338\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2259 - val_loss: 0.2159\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2101 - val_loss: 0.2019\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1977 - val_loss: 0.1910\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1882 - val_loss: 0.1829\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1808 - val_loss: 0.1761\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1747 - val_loss: 0.1706\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1695 - val_loss: 0.1656\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1648 - val_loss: 0.1612\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1605 - val_loss: 0.1569\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1565 - val_loss: 0.1533\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1528 - val_loss: 0.1496\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1494 - val_loss: 0.1463\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1463 - val_loss: 0.1433\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1433 - val_loss: 0.1404\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1406 - val_loss: 0.1378\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1381 - val_loss: 0.1354\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1357 - val_loss: 0.1331\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1334 - val_loss: 0.1308\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1312 - val_loss: 0.1287\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1292 - val_loss: 0.1267\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1272 - val_loss: 0.1248\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1253 - val_loss: 0.1229\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1235 - val_loss: 0.1212\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1218 - val_loss: 0.1196\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1202 - val_loss: 0.1180\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1188 - val_loss: 0.1166\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1173 - val_loss: 0.1152\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1160 - val_loss: 0.1139\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1148 - val_loss: 0.1128\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1137 - val_loss: 0.1116\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1126 - val_loss: 0.1106\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1116 - val_loss: 0.1096\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1107 - val_loss: 0.1087\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1098 - val_loss: 0.1079\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1090 - val_loss: 0.1071\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1083 - val_loss: 0.1063\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1076 - val_loss: 0.1057\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1069 - val_loss: 0.1050\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1063 - val_loss: 0.1045\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1057 - val_loss: 0.1039\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1052 - val_loss: 0.1034\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1047 - val_loss: 0.1029\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1042 - val_loss: 0.1025\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1038 - val_loss: 0.1020\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1034 - val_loss: 0.1017\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1030 - val_loss: 0.1013\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1026 - val_loss: 0.1009\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11adb550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhITBQYIiISEwWGiIjE5P8D97rUOu+0uNcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e0b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b0dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder (VAE)\n",
    "Variational autoencoders are a slightly more modern and interesting take on autoencoding.\n",
    "\n",
    "What is a variational autoencoder, you ask? It's a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some notions:\n",
    "1. $X$: data that we want to model a.k.a the animal\n",
    "2. $z$: latent variable a.k.a our imagination\n",
    "3. $P(X)$: probability distribution of the data, i.e. that animal kingdom\n",
    "4. $P(z)$: probability distribution of latent variable, i.e. our brain, the source of our imagination\n",
    "5. $P(X|z)$: distribution of generating data given latent variable, e.g. turning imagination into real animal\n",
    "\n",
    "\n",
    "Our objective here is to model the data, hence we want to find $P(X)$ Using the law of probability, we could find it in relation with $z$ as follows:\n",
    "<h1><center>$P(X) = \\int P(X|z)P(z)dz$</center></h1>\n",
    "that is, we marginalize out $z$ from the joint probability distribution $P(X,z)$.\n",
    "\n",
    "The idea of VAE is to infer $P(z)$ using $P(z|X)$. This is make a lot of sense if we think about it: we want to make our latent variable likely under our data. Talking in term of our fable example, we want to limit our imagination only on animal kingdom domain, so we shouldnt imagine about things like root, leaf, tyre, glass, GPU, refrigerator, doormat,  as its unlikely that those things have anything to do with things that come from the animal kingdom. Right?\n",
    "\n",
    "But the problem is, we have to infer that distribution $P(z|X)$, as we dont know it yet. In VAE, as it name suggests, we infer $P(z|X)$ using a method called Variational Inference (VI). VI is one of the popular choice of method in bayesian inference, the other one being MCMC method. The main idea of VI is to pose the inference by approach it as an optimization problem. How? By modeling the true distribution $P(z|X)$ using simpler distribution that is easy to evaluate, e.g. Gaussian, and minimize the difference between those two distribution using KL divergence metric, which tells us how difference it is $P$ and $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KullbackLeibler divergence\n",
    "Alright, now lets say we want to infer $P(z|X)$ using $Q(z|X)$. The KL divergence then formulated as follows:\n",
    "<h1><center>$D_{KL}[Q[z|X)||P(z|X)] = \\sum_z Q(z|X) \\log \\frac{Q(z|X)}{P(z|X)} = E_Q[\\log Q(z|X) - \\log P(z|X)]$</center></h1>\n",
    "# What KL-Divergence do?\n",
    "* allows use to compare 2 probability distributions\n",
    "* if $Q $ is the same as  $P$, then KLD = 0\n",
    "* if $Q$ is different from  $P$, KLD > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cost function\n",
    "The cost function we want to minimise is the negative of the evidence lower bound: 'ELBO':\n",
    "<h1><center>$ELBO = E[\\log P(X|z)] - D_{KL} [Q(z|X) ||P(z)]$</center></h1>\n",
    "\n",
    "The first term is $E[\\log P(X|z)]$ is the cross entropy we know. \n",
    "The second term is the KL divergence between the prior $P(z)$ and our latent model. We can choose the prior distribution any distribution we want, but it is much simpler to use normal distribution: $P(z) = N(0,1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL distribution between two normal distribution\n",
    "I am using book: The Matrix Cookbook from: http://coin.wne.uw.edu.pl/pbiernacki/matrix_cookbook.pdf\n",
    "1. $Q(z|X) = N(\\mu_1, \\Sigma_1^2)$\n",
    "2. $P(z) = N(\\mu_2, \\Sigma_2^2)$\n",
    "3. $D_{KL}[Q(z|X)||P(z:X)] = \\int P(z) [\\log P(z) - \\log Q(z|X)] dz$\n",
    "4. $D_{KL}[N(\\mu_1, \\Sigma_1)||N(\\mu_2,\\Sigma_2)]= \\frac{1}{2} [\\log \\frac{|\\Sigma_2|}{|\\Sigma_1|} - d  + tr{\\Sigma_2^{-1}\\Sigma_1} + (\\mu_2-\\mu_1)^T\\Sigma_2^{-1}(\\mu_2-\\mu_1)]$\n",
    "4. $d$ is the dimension of the latent vector.\n",
    "\n",
    "If we have $d=1$, and $P(x) = N(0,1)$ then the formula becomes very simple.\n",
    "$KL [N(\\mu, \\Sigma^2) || N(0,1)  ] = \\frac{1}{2}(\\log(\\Sigma) -1  + \\Sigma + \\mu^2)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD(N(3,2), N(0,1)) = 5.30685 , value =  5.34657359028\n",
      "KLD(N(3,1), N(2.9,1)) = 0.00499999\n",
      "KLD(N(3,1), N(3,1)) = 0.0\n"
     ]
    }
   ],
   "source": [
    "#tensor flow allows you to get the KL between two distribution...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as dis\n",
    "Normal = tf.contrib.distributions.Normal\n",
    "t = dis.kl_divergence(Normal(3.0, 2.0), Normal(0.0, 1.0))\n",
    "t2  =  dis.kl_divergence(Normal(3.0, 1.0), Normal(2.9,1.0))\n",
    "t3 =  dis.kl_divergence(Normal(3.0, 1.0), Normal(3.0,1.0))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    t_val = session.run(t)\n",
    "    print ('KLD(N(3,2), N(0,1)) =', t_val, \", value = \", .5*(np.log(2)  - 1  + 2.0 + 3**2 ))\n",
    "    t_val = session.run(t2)\n",
    "    print('KLD(N(3,1), N(2.9,1)) =', t_val)\n",
    "    t_val = session.run(t3)\n",
    "    print('KLD(N(3,1), N(3,1)) =', t_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implementing the variational auto encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#hyper parameters\n",
    "batch_size = 200\n",
    "latent_dim = 2\n",
    "intermediate_dim = 625\n",
    "epochs = 150\n",
    "epsilon_std = 1.0\n",
    "\n",
    "\n",
    "#data\n",
    "original_dim = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "#latent variables\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(set(y_test))))\n",
    "colors = colors[np.asarray(y_test)]\n",
    "\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=colors)\n",
    "m = cm.ScalarMappable(cmap=cm.jet)\n",
    "m.set_array(colors)\n",
    "plt.colorbar(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Application to image denoising\n",
    "Let's put our convolutional autoencoder to work on an image denoising problem. It's simple: we will train the autoencoder to map noisy digits images to clean digits images.\n",
    "\n",
    "Here's how we will generate synthetic noisy digits: we just apply a gaussian noise matrix and clip the images between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add gaussian noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n+1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you squint you can still recognize them, but barely. Can our autoencoder learn to recover the original digits? Let's find out.\n",
    "\n",
    "Compared to the previous convolutional autoencoder, in order to improve the quality of the reconstructed, we'll use a slightly different model with more filters per layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it for 50 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the results. Top, the noisy digits fed to the network, and bottom, the digits are reconstructed by the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converges to a loss of 0.094, significantly better than our previous models (this is in large part due to the higher entropic capacity of the encoded representation, 128 dimensions vs. 32 previously). Let's take a look at the reconstructed digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_train_noisy)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n+1):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_train_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
